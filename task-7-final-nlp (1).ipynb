{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4493396,"sourceType":"datasetVersion","datasetId":2628359}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom torch.utils.data import Dataset\nimport torch\nimport pandas as pd\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, EarlyStoppingCallback","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T10:56:33.166294Z","iopub.execute_input":"2025-05-04T10:56:33.166636Z","iopub.status.idle":"2025-05-04T10:56:33.171679Z","shell.execute_reply.started":"2025-05-04T10:56:33.166611Z","shell.execute_reply":"2025-05-04T10:56:33.170685Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/students-anxiety-and-depression-dataset/dataset.xlsx')\ndf = df.dropna(subset=[\"text\", \"label\"])\n\ntexts = df[\"text\"].astype(str).tolist()\nlabels = df[\"label\"].astype(int).tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T10:56:33.173025Z","iopub.execute_input":"2025-05-04T10:56:33.173314Z","iopub.status.idle":"2025-05-04T10:56:34.009132Z","shell.execute_reply.started":"2025-05-04T10:56:33.173285Z","shell.execute_reply":"2025-05-04T10:56:34.008511Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T10:56:34.009818Z","iopub.execute_input":"2025-05-04T10:56:34.010288Z","iopub.status.idle":"2025-05-04T10:56:34.030850Z","shell.execute_reply.started":"2025-05-04T10:56:34.010268Z","shell.execute_reply":"2025-05-04T10:56:34.030177Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                text  label\n0                                         oh my gosh    1.0\n1  trouble sleeping, confused mind, restless hear...    1.0\n2  All wrong, back off dear, forward doubt. Stay ...    1.0\n3  I've shifted my focus to something else but I'...    1.0\n4  I'm restless and restless, it's been a month n...    1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>oh my gosh</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>trouble sleeping, confused mind, restless hear...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>All wrong, back off dear, forward doubt. Stay ...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I've shifted my focus to something else but I'...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>I'm restless and restless, it's been a month n...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2).to(\"cuda\")  # ✅ Move to GPU\n\nclass AnxietyDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=128):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        encoding = self.tokenizer(\n            self.texts[idx],\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T10:56:34.032829Z","iopub.execute_input":"2025-05-04T10:56:34.033998Z","iopub.status.idle":"2025-05-04T10:56:37.353915Z","shell.execute_reply.started":"2025-05-04T10:56:34.033971Z","shell.execute_reply":"2025-05-04T10:56:37.353299Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"726431409bcf4607a3d88e3cb70840fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39f4aa98087c4bd682df3bd5ceabaf38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46d788f3afbc42c78f9508f1068f32cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb675b1d0a594b749c3018b473d66de4"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1c4b48275d44b26ab04403a5cf49f15"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)\n\ntrain_dataset = AnxietyDataset(train_texts, train_labels, tokenizer)\nval_dataset = AnxietyDataset(val_texts, val_labels, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T10:56:37.354655Z","iopub.execute_input":"2025-05-04T10:56:37.354927Z","iopub.status.idle":"2025-05-04T10:56:37.362726Z","shell.execute_reply.started":"2025-05-04T10:56:37.354899Z","shell.execute_reply":"2025-05-04T10:56:37.362063Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Training config\ntraining_args = TrainingArguments(\n    output_dir=\"./bert_anxiety\",\n    num_train_epochs=3,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"eval_loss\",\n    greater_is_better=False,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=DataCollatorWithPadding(tokenizer), \n    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T10:56:37.363410Z","iopub.execute_input":"2025-05-04T10:56:37.363726Z","iopub.status.idle":"2025-05-04T10:56:37.429748Z","shell.execute_reply.started":"2025-05-04T10:56:37.363697Z","shell.execute_reply":"2025-05-04T10:56:37.429001Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T10:56:37.430569Z","iopub.execute_input":"2025-05-04T10:56:37.430814Z","iopub.status.idle":"2025-05-04T11:02:09.087412Z","shell.execute_reply.started":"2025-05-04T10:56:37.430789Z","shell.execute_reply":"2025-05-04T11:02:09.086790Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1047' max='1047' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1047/1047 05:28, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.105600</td>\n      <td>0.046259</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.006400</td>\n      <td>0.042624</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000900</td>\n      <td>0.053422</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1047, training_loss=0.04916803249128611, metrics={'train_runtime': 331.2373, 'train_samples_per_second': 50.502, 'train_steps_per_second': 3.161, 'total_flos': 1100330433515520.0, 'train_loss': 0.04916803249128611, 'epoch': 3.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"import os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n\nmax_words = 5000\nmax_len = 100\n\ntokenizer_lstm = Tokenizer()\ntokenizer_lstm.fit_on_texts(texts)\nX = tokenizer_lstm.texts_to_sequences(texts)\nX = pad_sequences(X, maxlen=max_len)\n\nvocab_size = len(tokenizer_lstm.word_index) + 1\n\nX_train, X_val, y_train, y_val = train_test_split(X, labels, test_size=0.2, random_state=42)\n\n\nmodel_lstm = Sequential()\nmodel_lstm.add(Embedding(input_dim=vocab_size, output_dim=64, input_length=max_len))\nmodel_lstm.add(LSTM(64, implementation=1))  # ✅ Forces CPU-compatible version\nmodel_lstm.add(Dense(1, activation='sigmoid'))\n\nmodel_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:02:52.033461Z","iopub.execute_input":"2025-05-04T11:02:52.033786Z","iopub.status.idle":"2025-05-04T11:02:52.403900Z","shell.execute_reply.started":"2025-05-04T11:02:52.033764Z","shell.execute_reply":"2025-05-04T11:02:52.403020Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\nI0000 00:00:1746356572.346307      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11494 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1746356572.346975      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 12632 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\n\nX_train = np.array(X_train).astype(\"int32\")\nX_val = np.array(X_val).astype(\"int32\")\ny_train = np.array(y_train).astype(\"float32\")\ny_val = np.array(y_val).astype(\"float32\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:03:54.408787Z","iopub.execute_input":"2025-05-04T11:03:54.409095Z","iopub.status.idle":"2025-05-04T11:03:54.417137Z","shell.execute_reply.started":"2025-05-04T11:03:54.409073Z","shell.execute_reply":"2025-05-04T11:03:54.416438Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"history = model_lstm.fit(\n    X_train, y_train,\n    epochs=5,\n    batch_size=16,\n    validation_data=(X_val, y_val)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:03:57.079325Z","iopub.execute_input":"2025-05-04T11:03:57.080099Z","iopub.status.idle":"2025-05-04T11:04:14.914867Z","shell.execute_reply.started":"2025-05-04T11:03:57.080069Z","shell.execute_reply":"2025-05-04T11:04:14.914300Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1746356641.501618    3094 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8885 - loss: 0.3457 - val_accuracy: 0.9828 - val_loss: 0.0674\nEpoch 2/5\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9875 - loss: 0.0479 - val_accuracy: 0.9885 - val_loss: 0.0484\nEpoch 3/5\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9945 - loss: 0.0210 - val_accuracy: 0.9857 - val_loss: 0.0532\nEpoch 4/5\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9973 - loss: 0.0100 - val_accuracy: 0.9842 - val_loss: 0.0662\nEpoch 5/5\n\u001b[1m349/349\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0124 - val_accuracy: 0.9878 - val_loss: 0.0519\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport torch\n\n# Predict\npred_output = trainer.predict(val_dataset)\npred_logits = torch.tensor(pred_output.predictions)\npreds = torch.argmax(pred_logits, dim=1)\ntrue_labels = torch.tensor(pred_output.label_ids)\n\n# Evaluation\nprint(\" BERT Classification Report:\")\nprint(classification_report(true_labels, preds, digits=3))\n\nprint(\" Confusion Matrix:\")\nprint(confusion_matrix(true_labels, preds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:24:59.474530Z","iopub.execute_input":"2025-05-04T11:24:59.475153Z","iopub.status.idle":"2025-05-04T11:25:07.547034Z","shell.execute_reply.started":"2025-05-04T11:24:59.475128Z","shell.execute_reply":"2025-05-04T11:25:07.546236Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":" BERT Classification Report:\n              precision    recall  f1-score   support\n\n           0      0.997     0.993     0.995      1235\n           1      0.945     0.975     0.960       159\n\n    accuracy                          0.991      1394\n   macro avg      0.971     0.984     0.977      1394\nweighted avg      0.991     0.991     0.991      1394\n\n Confusion Matrix:\n[[1226    9]\n [   4  155]]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\n# Get predictions (probabilities → binary)\ny_pred = (model_lstm.predict(X_val) > 0.5).astype(\"int32\")\n\n# Print classification report\nprint(\"\\n LSTM Classification Report:\")\nprint(classification_report(y_val, y_pred))\n\n# Print confusion matrix\nprint(\" Confusion Matrix:\")\nprint(confusion_matrix(y_val, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:29:10.356674Z","iopub.execute_input":"2025-05-04T11:29:10.356959Z","iopub.status.idle":"2025-05-04T11:29:10.589249Z","shell.execute_reply.started":"2025-05-04T11:29:10.356941Z","shell.execute_reply":"2025-05-04T11:29:10.588533Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n\n LSTM Classification Report:\n              precision    recall  f1-score   support\n\n         0.0       0.99      0.99      0.99      1235\n         1.0       0.96      0.94      0.95       159\n\n    accuracy                           0.99      1394\n   macro avg       0.97      0.97      0.97      1394\nweighted avg       0.99      0.99      0.99      1394\n\n Confusion Matrix:\n[[1228    7]\n [  10  149]]\n","output_type":"stream"}],"execution_count":18}]}