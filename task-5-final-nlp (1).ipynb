{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7882142,"sourceType":"datasetVersion","datasetId":4626328}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"pip install flair","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-05-04T11:19:52.809095Z","iopub.execute_input":"2025-05-04T11:19:52.809419Z","iopub.status.idle":"2025-05-04T11:21:36.462190Z","shell.execute_reply.started":"2025-05-04T11:19:52.809396Z","shell.execute_reply":"2025-05-04T11:21:36.460651Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport spacy\nfrom flair.models import SequenceTagger\nfrom flair.data import Sentence\nfrom transformers import BertTokenizerFast, BertForTokenClassification, pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:21:56.229782Z","iopub.execute_input":"2025-05-04T11:21:56.230400Z","iopub.status.idle":"2025-05-04T11:22:34.360269Z","shell.execute_reply.started":"2025-05-04T11:21:56.230348Z","shell.execute_reply":"2025-05-04T11:22:34.359415Z"}},"outputs":[{"name":"stderr","text":"2025-05-04 11:22:17.029529: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746357737.265670      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746357737.329034      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/news-articles-classification-dataset-for-nlp-and-ml/education_data.csv')\ntexts = df['description'].dropna().astype(str).tolist()[:3] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:22:34.361612Z","iopub.execute_input":"2025-05-04T11:22:34.362441Z","iopub.status.idle":"2025-05-04T11:22:34.489656Z","shell.execute_reply.started":"2025-05-04T11:22:34.362405Z","shell.execute_reply":"2025-05-04T11:22:34.488676Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"nlp = spacy.load(\"en_core_web_sm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:22:34.490614Z","iopub.execute_input":"2025-05-04T11:22:34.490895Z","iopub.status.idle":"2025-05-04T11:22:35.355611Z","shell.execute_reply.started":"2025-05-04T11:22:34.490874Z","shell.execute_reply":"2025-05-04T11:22:35.354621Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# NER with spaCy\nprint(\"Named Entity Recognition with spaCy\")\nnlp_spacy = spacy.load(\"en_core_web_sm\")\n\nfor i, text in enumerate(texts, 1):\n    doc = nlp_spacy(text)\n    print(f\"\\n Text {i}: {text}\\nEntities:\")\n    for ent in doc.ents:\n        print(f\" - {ent.text:30} ➤ {ent.label_}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:22:35.358238Z","iopub.execute_input":"2025-05-04T11:22:35.358529Z","iopub.status.idle":"2025-05-04T11:22:36.144032Z","shell.execute_reply.started":"2025-05-04T11:22:35.358507Z","shell.execute_reply":"2025-05-04T11:22:36.143218Z"}},"outputs":[{"name":"stdout","text":"Named Entity Recognition with spaCy\n\n Text 1: CUET PG 2024: UGC said that the list of participating institutions displayed on the NTA website is dynamic and will be updated to include the name of the new universities after they are registered.\nEntities:\n - CUET                           ➤ ORG\n - 2024                           ➤ CARDINAL\n - UGC                            ➤ ORG\n - NTA                            ➤ ORG\n\n Text 2: On April 10, 2023 TCS had announced that it had been selected by Oxford University for the delivery of most of the university’s admissions tests from 2023 onwards.\nEntities:\n - April 10, 2023                 ➤ DATE\n - TCS                            ➤ ORG\n - Oxford University              ➤ ORG\n - 2023                           ➤ DATE\n\n Text 3: AISHE Report 2021-22: The enrollment in STEM (at UG, PG, MPhil and PhD levels) is 98,49,488, out of which 56,56,488 are men and 41,93,000 are women.\nEntities:\n - AISHE Report                   ➤ ORG\n - 2021-22                        ➤ DATE\n - UG                             ➤ GPE\n - PG                             ➤ GPE\n - MPhil                          ➤ ORG\n - PhD                            ➤ WORK_OF_ART\n - 98,49,488                      ➤ DATE\n - 56,56,488                      ➤ CARDINAL\n - 41,93,000                      ➤ CARDINAL\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"print(\"Named Entity Recognition with BERT\")\n\ntokenizer_bert_ner = BertTokenizerFast.from_pretrained(\"dslim/bert-base-NER\")\nmodel_bert_ner = BertForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\nner_pipeline = pipeline(\"ner\", model=model_bert_ner, tokenizer=tokenizer_bert_ner, aggregation_strategy=\"simple\")\n\nfor idx, text in enumerate(texts, 1):\n    print(f\"\\n Text {idx}: {text}\\nEntities:\")\n    ner_results = ner_pipeline(text)\n    for ent in ner_results:\n        print(f\" • {ent['word']:25s} ➤ {ent['entity_group']} ({ent['score']:.2f})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:22:36.144871Z","iopub.execute_input":"2025-05-04T11:22:36.145197Z","iopub.status.idle":"2025-05-04T11:22:40.585420Z","shell.execute_reply.started":"2025-05-04T11:22:36.145174Z","shell.execute_reply":"2025-05-04T11:22:40.584526Z"}},"outputs":[{"name":"stdout","text":"Named Entity Recognition with BERT\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/59.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e6e91d4df504ba9b3ceaf589e3d475a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"923a0daf20674c9b8296d47ba8ac4632"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"738b0f62bd1e40079273b80c55806c6d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70962caec4344b8baaef98fc3d60f475"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/829 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71555165018a460db0002a3028f34736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3913a9b7cff64d3f960a5ff4aabd35f5"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nDevice set to use cpu\n","output_type":"stream"},{"name":"stdout","text":"\n Text 1: CUET PG 2024: UGC said that the list of participating institutions displayed on the NTA website is dynamic and will be updated to include the name of the new universities after they are registered.\nEntities:\n • P                         ➤ ORG (0.54)\n • UGC                       ➤ ORG (1.00)\n • NTA                       ➤ ORG (0.98)\n\n Text 2: On April 10, 2023 TCS had announced that it had been selected by Oxford University for the delivery of most of the university’s admissions tests from 2023 onwards.\nEntities:\n • TCS                       ➤ ORG (1.00)\n • Oxford University         ➤ ORG (1.00)\n\n Text 3: AISHE Report 2021-22: The enrollment in STEM (at UG, PG, MPhil and PhD levels) is 98,49,488, out of which 56,56,488 are men and 41,93,000 are women.\nEntities:\n • AISHE                     ➤ ORG (0.72)\n • Report                    ➤ MISC (0.68)\n • ST                        ➤ MISC (0.55)\n • MP                        ➤ MISC (0.58)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"print(\"POS Tagging with spaCy\")\n\nfor i, text in enumerate(texts, 1):\n    doc = nlp_spacy(text)\n    print(f\"\\n Text {i}: {text[:90]}...\")\n    print(\"POS Tags (spaCy):\")\n    for token in doc[:20]:\n        print(f\"{token.text:<12} ➤ {token.pos_}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:22:40.586570Z","iopub.execute_input":"2025-05-04T11:22:40.586964Z","iopub.status.idle":"2025-05-04T11:22:40.630704Z","shell.execute_reply.started":"2025-05-04T11:22:40.586928Z","shell.execute_reply":"2025-05-04T11:22:40.629689Z"}},"outputs":[{"name":"stdout","text":"POS Tagging with spaCy\n\n Text 1: CUET PG 2024: UGC said that the list of participating institutions displayed on the NTA we...\nPOS Tags (spaCy):\nCUET         ➤ PROPN\nPG           ➤ PROPN\n2024         ➤ NUM\n:            ➤ PUNCT\nUGC          ➤ PROPN\nsaid         ➤ VERB\nthat         ➤ SCONJ\nthe          ➤ DET\nlist         ➤ NOUN\nof           ➤ ADP\nparticipating ➤ VERB\ninstitutions ➤ NOUN\ndisplayed    ➤ VERB\non           ➤ ADP\nthe          ➤ DET\nNTA          ➤ PROPN\nwebsite      ➤ NOUN\nis           ➤ AUX\ndynamic      ➤ ADJ\nand          ➤ CCONJ\n\n Text 2: On April 10, 2023 TCS had announced that it had been selected by Oxford University for the...\nPOS Tags (spaCy):\nOn           ➤ ADP\nApril        ➤ PROPN\n10           ➤ NUM\n,            ➤ PUNCT\n2023         ➤ NUM\nTCS          ➤ PROPN\nhad          ➤ AUX\nannounced    ➤ VERB\nthat         ➤ SCONJ\nit           ➤ PRON\nhad          ➤ AUX\nbeen         ➤ AUX\nselected     ➤ VERB\nby           ➤ ADP\nOxford       ➤ PROPN\nUniversity   ➤ PROPN\nfor          ➤ ADP\nthe          ➤ DET\ndelivery     ➤ NOUN\nof           ➤ ADP\n\n Text 3: AISHE Report 2021-22: The enrollment in STEM (at UG, PG, MPhil and PhD levels) is 98,49,48...\nPOS Tags (spaCy):\nAISHE        ➤ PROPN\nReport       ➤ PROPN\n2021         ➤ NUM\n-            ➤ SYM\n22           ➤ NUM\n:            ➤ PUNCT\nThe          ➤ DET\nenrollment   ➤ NOUN\nin           ➤ ADP\nSTEM         ➤ PROPN\n(            ➤ PUNCT\nat           ➤ ADP\nUG           ➤ PROPN\n,            ➤ PUNCT\nPG           ➤ PROPN\n,            ➤ PUNCT\nMPhil        ➤ PROPN\nand          ➤ CCONJ\nPhD          ➤ NOUN\nlevels       ➤ NOUN\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(\" POS Tagging with BERT-based Flair\")\n\ntagger = SequenceTagger.load(\"pos\")\n\nfor i, text in enumerate(texts, 1):\n    sentence = Sentence(text[:100])\n    tagger.predict(sentence)\n    print(f\"\\n BERT-based POS Tags for Text {i}:\")\n    for token in sentence.tokens[:20]:\n        tag = token.annotation_layers['pos'][0].value if 'pos' in token.annotation_layers else 'N/A'\n        print(f\"{token.text:<12} ➤ {tag}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:22:40.631773Z","iopub.execute_input":"2025-05-04T11:22:40.632157Z","iopub.status.idle":"2025-05-04T11:22:45.523937Z","shell.execute_reply.started":"2025-05-04T11:22:40.632118Z","shell.execute_reply":"2025-05-04T11:22:45.523097Z"}},"outputs":[{"name":"stdout","text":" POS Tagging with BERT-based Flair\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/249M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aef3771cb8394b0bbd9895a97db00003"}},"metadata":{}},{"name":"stdout","text":"2025-05-04 11:22:42,683 SequenceTagger predicts: Dictionary with 53 tags: <unk>, O, UH, ,, VBD, PRP, VB, PRP$, NN, RB, ., DT, JJ, VBP, VBG, IN, CD, NNS, NNP, WRB, VBZ, WDT, CC, TO, MD, VBN, WP, :, RP, EX, JJR, FW, XX, HYPH, POS, RBR, JJS, PDT, NNPS, RBS, AFX, WP$, -LRB-, -RRB-, ``, '', LS, $, SYM, ADD\n\n BERT-based POS Tags for Text 1:\nCUET         ➤ NNP\nPG           ➤ NNP\n2024         ➤ CD\n:            ➤ :\nUGC          ➤ NNP\nsaid         ➤ VBD\nthat         ➤ IN\nthe          ➤ DT\nlist         ➤ NN\nof           ➤ IN\nparticipating ➤ VBG\ninstitutions ➤ NNS\ndisplayed    ➤ VBN\non           ➤ IN\nthe          ➤ DT\nNTA          ➤ NNP\nwebsite      ➤ NN\nis           ➤ VBZ\nd            ➤ NN\n\n BERT-based POS Tags for Text 2:\nOn           ➤ IN\nApril        ➤ NNP\n10           ➤ CD\n,            ➤ ,\n2023         ➤ CD\nTCS          ➤ NNP\nhad          ➤ VBD\nannounced    ➤ VBN\nthat         ➤ IN\nit           ➤ PRP\nhad          ➤ VBD\nbeen         ➤ VBN\nselected     ➤ VBN\nby           ➤ IN\nOxford       ➤ NNP\nUniversity   ➤ NNP\nfor          ➤ IN\nthe          ➤ DT\ndelivery     ➤ NN\n\n BERT-based POS Tags for Text 3:\nAISHE        ➤ NNP\nReport       ➤ NNP\n2021-22      ➤ CD\n:            ➤ :\nThe          ➤ DT\nenrollment   ➤ NN\nin           ➤ IN\nSTEM         ➤ NNP\n(            ➤ :\nat           ➤ IN\nUG           ➤ NNP\n,            ➤ ,\nPG           ➤ NNP\n,            ➤ ,\nMPhil        ➤ NNP\nand          ➤ CC\nPhD          ➤ NNP\nlevels       ➤ NNS\n)            ➤ -RRB-\nis           ➤ VBZ\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\ntagger_flair = SequenceTagger.load(\"flair/upos-english\")  # Universal POS tags\n\ntrue_tags = []\npred_tags = []\n\nfor text in texts:\n    doc_spacy = nlp_spacy(text)\n    sentence_flair = Sentence(text)\n    tagger_flair.predict(sentence_flair)\n\n    min_len = min(len(doc_spacy), len(sentence_flair))\n\n    for i in range(min_len):\n        spacy_tag = doc_spacy[i].pos_\n        flair_tag = sentence_flair[i].labels[0].value if sentence_flair[i].labels else 'N/A'\n        true_tags.append(spacy_tag)\n        pred_tags.append(flair_tag)\n\nprint(\"\\n POS Tagging Evaluation (Flair vs spaCy):\\n\")\nprint(classification_report(true_tags, pred_tags, zero_division=0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:22:45.525042Z","iopub.execute_input":"2025-05-04T11:22:45.525390Z","iopub.status.idle":"2025-05-04T11:23:01.340696Z","shell.execute_reply.started":"2025-05-04T11:22:45.525361Z","shell.execute_reply":"2025-05-04T11:23:01.339886Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/244M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"081c1358506c42d4a4516e9ead07a5bf"}},"metadata":{}},{"name":"stdout","text":"2025-05-04 11:22:56,721 SequenceTagger predicts: Dictionary with 19 tags: <unk>, NOUN, VERB, PUNCT, ADP, DET, PROPN, PRON, ADJ, ADV, CCONJ, PART, NUM, AUX, INTJ, SYM, X, <START>, <STOP>\n\n POS Tagging Evaluation (Flair vs spaCy):\n\n              precision    recall  f1-score   support\n\n         ADJ       1.00      0.67      0.80         3\n         ADP       0.53      0.62      0.57        13\n         ADV       0.00      0.00      0.00         1\n         AUX       1.00      0.10      0.18        10\n       CCONJ       0.25      0.33      0.29         3\n         DET       1.00      0.57      0.73         7\n        NOUN       0.75      0.69      0.72        13\n         NUM       0.38      0.89      0.53         9\n        PART       1.00      0.50      0.67         2\n        PRON       0.50      0.67      0.57         3\n       PROPN       0.73      0.57      0.64        14\n       PUNCT       0.40      0.40      0.40        10\n       SCONJ       0.00      0.00      0.00         3\n         SYM       0.00      0.00      0.00         1\n        VERB       0.46      0.75      0.57         8\n\n    accuracy                           0.54       100\n   macro avg       0.53      0.45      0.44       100\nweighted avg       0.62      0.54      0.52       100\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\n\nspacy_entities = []\nfor i, text in enumerate(texts, 1):\n    doc = nlp_spacy(text)\n    for ent in doc.ents:\n        spacy_entities.append({'Text ID': i, 'Entity': ent.text.strip(), 'Label (spaCy)': ent.label_})\n\nbert_entities = []\nfor i, text in enumerate(texts, 1):\n    ner_results = ner_pipeline(text)\n    for ent in ner_results:\n        bert_entities.append({'Text ID': i, 'Entity': ent['word'].strip(), 'Label (BERT)': ent['entity_group']})\n\ndf_spacy = pd.DataFrame(spacy_entities)\ndf_bert = pd.DataFrame(bert_entities)\nmerged = pd.merge(df_spacy, df_bert, on=[\"Text ID\", \"Entity\"], how=\"outer\")\n\nmerged['Label (spaCy)'] = merged['Label (spaCy)'].fillna(\"None\")\nmerged['Label (BERT)'] = merged['Label (BERT)'].fillna(\"None\")\n\npd.set_option('display.max_rows', None)\nprint(merged.to_string(index=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T11:23:01.341591Z","iopub.execute_input":"2025-05-04T11:23:01.341968Z","iopub.status.idle":"2025-05-04T11:23:01.781269Z","shell.execute_reply.started":"2025-05-04T11:23:01.341938Z","shell.execute_reply":"2025-05-04T11:23:01.780337Z"}},"outputs":[{"name":"stdout","text":" Text ID            Entity Label (spaCy) Label (BERT)\n       1              2024      CARDINAL         None\n       1              CUET           ORG         None\n       1               NTA           ORG          ORG\n       1                 P          None          ORG\n       1               UGC           ORG          ORG\n       2              2023          DATE         None\n       2    April 10, 2023          DATE         None\n       2 Oxford University           ORG          ORG\n       2               TCS           ORG          ORG\n       3           2021-22          DATE         None\n       3         41,93,000      CARDINAL         None\n       3         56,56,488      CARDINAL         None\n       3         98,49,488          DATE         None\n       3             AISHE          None          ORG\n       3      AISHE Report           ORG         None\n       3                MP          None         MISC\n       3             MPhil           ORG         None\n       3                PG           GPE         None\n       3               PhD   WORK_OF_ART         None\n       3            Report          None         MISC\n       3                ST          None         MISC\n       3                UG           GPE         None\n","output_type":"stream"}],"execution_count":10}]}